{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import numpy as np\n",
    "\n",
    "from src.models.vision import get_encoder\n",
    "from src.data.process_demos import encode_demo\n",
    "from src.visualization.render_mp4 import create_mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(os.environ[\"FURNITURE_DATA_DIR\"])\n",
    "\n",
    "rollout_dir = base_dir / \"raw\" / \"sim_rollouts\"\n",
    "\n",
    "file_path = rollout_dir / \"index.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index the raw rollout data\n",
    "\n",
    "Now done in a standalone script `src.data.index_rollouts`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment an existing Zarr array with new data from the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/data/scratch/ankile/furniture-data/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_path = (\n",
    "    base_dir\n",
    "    / \"processed\"\n",
    "    / \"sim\"\n",
    "    / \"feature_separate_small\"\n",
    "    / \"vip\"\n",
    "    / \"one_leg\"\n",
    "    / \"data_aug.zarr\"\n",
    ")\n",
    "\n",
    "store = zarr.open(str(zarr_path), mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout_paths dataset already exists\n",
      "skills dataset does not exist\n"
     ]
    }
   ],
   "source": [
    "if \"rollout_paths\" not in store:\n",
    "    print(\"Creating rollout_paths dataset\")\n",
    "    store.create_dataset(\"rollout_paths\", shape=(0,), dtype=str)\n",
    "else:\n",
    "    print(\"rollout_paths dataset already exists\")\n",
    "\n",
    "# Remove the skills dataset if it exists\n",
    "if \"skills\" in store:\n",
    "    print(\"Removing skills dataset\")\n",
    "    del store[\"skills\"]\n",
    "else:\n",
    "    print(\"skills dataset does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the index file as a dataframe\n",
    "index = pd.read_csv(file_path)\n",
    "\n",
    "index = index[index[\"success\"] == True]\n",
    "\n",
    "# Get the paths to all the successful rollouts\n",
    "paths = index[\"path\"].values\n",
    "\n",
    "# Compare with the paths already in the zarr file\n",
    "zarr_paths = store[\"rollout_paths\"][:]\n",
    "paths = [p for p in paths if p not in zarr_paths]\n",
    "\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 461/461 [00:00<00:00, 803.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as test.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Just sanity check the index by loading a rollout\n",
    "with open(paths[0], \"rb\") as f:\n",
    "    rollout = pickle.load(f)\n",
    "\n",
    "vid1 = [o[\"color_image1\"] for o in rollout[\"observations\"]]\n",
    "vid2 = [o[\"color_image2\"] for o in rollout[\"observations\"]]\n",
    "vid = np.concatenate([vid1, vid2], axis=2)\n",
    "\n",
    "end_idx = np.argmax(rollout[\"rewards\"]) + 1\n",
    "\n",
    "create_mp4(vid[:end_idx], \"test.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an encoder\n",
    "encoder = get_encoder(\"vip\", freeze=True, device=\"cuda:0\")\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/451 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 451/451 [40:20<00:00,  5.37s/it]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the paths and add them to the zarr file\n",
    "end_index = store[\"episode_ends\"][-1]\n",
    "\n",
    "for path in tqdm(paths):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    end_idx = np.argmax(data[\"rewards\"]) + 1\n",
    "\n",
    "    store[\"action\"].append(data[\"actions\"][:end_idx])\n",
    "    store[\"rewards\"].append(data[\"rewards\"][:end_idx])\n",
    "\n",
    "    store[\"episode_ends\"].append([end_index := end_index + end_idx])\n",
    "    store[\"furniture\"].append([data[\"furniture\"]])\n",
    "\n",
    "    obs = data[\"observations\"][:end_idx]\n",
    "    demo_robot_states, demo_features1, demo_features2 = encode_demo(\n",
    "        encoder, batch_size, obs\n",
    "    )\n",
    "    store[\"robot_state\"].append(demo_robot_states)\n",
    "    store[\"feature1\"].append(demo_features1)\n",
    "    store[\"feature2\"].append(demo_features2)\n",
    "    store[\"rollout_paths\"].append([path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259640"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check length of actions after\n",
    "store[\"episode_ends\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
